# Web Data Integration me AI pÃ«r Rajonin e KosovÃ«s

## ğŸ“Š PÃ«rmbledhje

Ky dokument paraqet ide dhe strategji pÃ«r integrimin e tÃ« dhÃ«nave automatike nga web-i pÃ«rmes AI pÃ«r rajonin e KosovÃ«s nÃ« Smart Grid Analytics.

---

## ğŸ¯ Burimet e TÃ« DhÃ«nave pÃ«r KosovÃ«n

### 1. TÃ« DhÃ«na Moti (Weather Data) ğŸŒ¤ï¸

**Burime publike:**
- **OpenWeatherMap API**: TÃ« dhÃ«na reale pÃ«r PrishtinÃ«, Prizren, PejÃ«, Gjilan, MitrovicÃ«
- **Meteoblue API**: TÃ« dhÃ«na tÃ« detajuara pÃ«r rajonet e KosovÃ«s
- **MeteoKosova** (nÃ«se ka API publik): TÃ« dhÃ«na lokale
- **Weather Underground**: Historical dhe real-time data

**TÃ« dhÃ«nat e nevojshme:**
- Temperatura (Â°C)
- LagÃ«shtia (%)
- Presioni atmosferik (hPa)
- ShpejtÃ«sia e erÃ«s (km/h)
- Konsumimi i energjisÃ« korrelehet me temperaturÃ«n (ngrohje/freskim)

**Integrim:**
- Replace simulated weather data me real API calls
- Cache data pÃ«r tÃ« reduktuar API calls
- Fallback nÃ« simulated data nÃ«se API fails

---

### 2. TÃ« DhÃ«na tÃ« Ã‡mimeve tÃ« EnergjisÃ« âš¡

**Burime publike pÃ«r KosovÃ«n:**
- **KOSTT (Kosovo System Operator)**: TÃ« dhÃ«na publike tÃ« Ã§mimeve
- **Energy Regulatory Office (ERO)**: Ã‡mime dhe tarifa
- **KEK (Kosovo Energy Corporation)**: Ã‡mime pÃ«r konsumatorÃ«t
- Web scraping nga faqet zyrtare (nÃ«se nuk ka API)

**TÃ« dhÃ«nat e nevojshme:**
- Tarifa e energjisÃ« elektrike (â‚¬/kWh)
- Ã‡mime pÃ«r konsumatorÃ«t rezidencialÃ«/komercialÃ«
- Peak/Off-peak pricing (nÃ«se ka)
- Historical pricing trends

**AI Integration:**
- Web scraping me BeautifulSoup/Scrapy
- NLP pÃ«r extraction tÃ« Ã§mimeve nga PDF-Ã« dhe faqe web
- ML models pÃ«r parashikim Ã§mimesh tÃ« ardhshme

---

### 3. TÃ« DhÃ«na Demografike dhe Popullata ğŸ‘¥

**Burime:**
- **ASK (Agjencia e Statistikave tÃ« KosovÃ«s)**: Census data, statistikat e popullsisÃ«
- **World Bank Open Data**: Economic indicators pÃ«r KosovÃ«n
- **UN Data**: Development indicators

**TÃ« dhÃ«nat e nevojshme:**
- Popullata sipas rajonit (PrishtinÃ«, Prizren, PejÃ«, etj.)
- Rritja e popullsisÃ«
- Konsumi mesatar i energjisÃ« pÃ«r shtÃ«pi
- Economic indicators qÃ« ndikojnÃ« nÃ« konsum

---

### 4. TÃ« DhÃ«na tÃ« Konsumit tÃ« EnergjisÃ« ğŸ“Š

**Burime:**
- **KOSTT**: Real-time dhe historical consumption data
- **KEK**: Consumption statistics pÃ«r rajonet
- **Transparency Platform Kosovo**: Open data initiatives
- Web scraping nga dashboard-e publike

**TÃ« dhÃ«nat e nevojshme:**
- Total consumption pÃ«r KosovÃ«n (MW)
- Consumption sipas rajonit
- Peak hours dhe demand patterns
- Seasonal variations

---

### 5. TÃ« DhÃ«na tÃ« Prodhimit tÃ« EnergjisÃ« (Renewable) ğŸŒ±

**Burime:**
- **KOSTT**: Renewable energy production data
- **Ministry of Economic Development**: Policies dhe statistics
- **Solar/Wind farm operators**: Production data (nÃ«se publike)

**TÃ« dhÃ«nat e nevojshme:**
- Solar energy production (MW)
- Wind energy production (MW)
- Hydroelectric production (MW)
- Grid capacity dhe availability

---

### 6. TÃ« DhÃ«na tÃ« Trafikut dhe Urbanizimit ğŸš—

**Burime:**
- **Google Maps API**: Traffic data pÃ«r rajonet e KosovÃ«s
- **OpenStreetMap**: Geographic data
- **Municipality data**: Urban development plans

**PÃ«rdorimi:**
- Traffic patterns korrelojnÃ« me consumption (industrial areas)
- Urban development ndikon nÃ« demand tÃ« energjisÃ«
- Geographic data pÃ«r optimal sensor placement

---

## ğŸ¤– TeknologjitÃ« e AI pÃ«r Data Extraction

### 1. Web Scraping me AI

**LibraritÃ«:**
- **BeautifulSoup4**: HTML parsing
- **Scrapy**: Web crawling framework
- **Selenium**: Dynamic content (JavaScript rendering)
- **Playwright**: Modern browser automation

**AI Features:**
- **Natural Language Processing (NLP)**: Extract text nga PDF-Ã« dhe images
- **OCR (Tesseract/Google Vision)**: Extract text nga screenshots/images
- **LLM Integration (GPT-4/Claude)**: Extract structured data nga unstructured text

### 2. Document Processing

**LibraritÃ«:**
- **PyPDF2/pdfplumber**: PDF parsing
- **Pandas**: Data manipulation
- **LangChain**: Document processing me LLMs
- **unstructured**: AI-powered document parsing

**PÃ«rdorimi:**
- Extract data nga PDF reports (KOSTT, ERO)
- Convert tables nÃ« structured data
- Summarize dhe extract key metrics

### 3. API Integration me AI Enhancement

**Features:**
- **Rate limiting**: Respect API limits
- **Caching**: Redis pÃ«r tÃ« reduktuar API calls
- **Data validation**: AI pÃ«r tÃ« validuar tÃ« dhÃ«nat
- **Anomaly detection**: ML pÃ«r tÃ« detektuar data tÃ« pasakta

---

## ğŸ—ï¸ Arkitektura e Integrimit

### KomponentÃ«t e Reja:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Web Data Collector Service (AI-Powered)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Weather      â”‚  â”‚ Energy Price â”‚  â”‚ Consumption  â”‚ â”‚
â”‚  â”‚ Scraper      â”‚  â”‚ Scraper      â”‚  â”‚ Scraper      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ PDF Parser   â”‚  â”‚ NLP Engine   â”‚  â”‚ OCR Service  â”‚ â”‚
â”‚  â”‚ (AI)         â”‚  â”‚ (LLM)        â”‚  â”‚ (Tesseract)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         Data Validation & Enrichment (AI)         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     Kafka     â”‚
                â”‚   (Topics)    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Existing Processing Pipeline â”‚
        â”‚  (Spark, PostgreSQL, etc.)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Implementimi i Rekomanduar

### Faza 1: Weather Data Integration (Prioritet i LartÃ«)

**Service**: `kosovo-weather-collector`

**Features:**
- Integrim me OpenWeatherMap API pÃ«r qytetet e KosovÃ«s
- Scheduled collection (Ã§do orÃ«)
- Data enrichment me AI (weather patterns prediction)
- Integration me existing weather-producer-service

**Kodi i Shembullit:**
```python
# docker/kosovo-weather-collector/app.py
import requests
import json
from kafka import KafkaProducer

KOSOVO_CITIES = {
    'prishtina': {'lat': 42.6629, 'lon': 21.1655},
    'prizren': {'lat': 42.2139, 'lon': 20.7397},
    'peje': {'lat': 42.6609, 'lon': 20.2891},
    'gjilan': {'lat': 42.4639, 'lon': 21.4694},
    'mitrovice': {'lat': 42.8833, 'lon': 20.8667}
}

def collect_kosovo_weather():
    """Collect real weather data pÃ«r qytetet e KosovÃ«s"""
    weather_data = []
    
    for city, coords in KOSOVO_CITIES.items():
        # API call to OpenWeatherMap
        url = f"http://api.openweathermap.org/data/2.5/weather"
        params = {
            'lat': coords['lat'],
            'lon': coords['lon'],
            'appid': os.getenv('OPENWEATHER_API_KEY'),
            'units': 'metric'
        }
        response = requests.get(url, params=params)
        data = response.json()
        
        weather_data.append({
            'city': city,
            'temperature': data['main']['temp'],
            'humidity': data['main']['humidity'],
            'pressure': data['main']['pressure'],
            'wind_speed': data['wind']['speed'],
            'condition': data['weather'][0]['main'],
            'timestamp': datetime.utcnow().isoformat()
        })
    
    return weather_data
```

---

### Faza 2: Energy Price Scraper (AI-Powered)

**Service**: `kosovo-energy-price-collector`

**Features:**
- Web scraping nga faqet zyrtare (KOSTT, ERO)
- PDF parsing pÃ«r tariff reports
- NLP pÃ«r extraction tÃ« Ã§mimeve
- ML pÃ«r parashikim Ã§mimesh

**Kodi i Shembullit:**
```python
# docker/kosovo-energy-price-collector/app.py
from bs4 import BeautifulSoup
import requests
from langchain import LLMChain
from langchain.llms import OpenAI

def scrape_energy_prices():
    """Scrape energy prices nga faqet zyrtare"""
    # Scrape from KOSTT website
    url = "https://kostt.com/PublicConsumer/Tariff"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Extract tariff information
    # Use AI/LLM pÃ«r tÃ« extract structured data nga unstructured HTML
    # ...
    
def extract_from_pdf(pdf_path):
    """Extract tariff data nga PDF reports"""
    # Use pdfplumber ose PyPDF2
    # Use LLM pÃ«r tÃ« extract structured data
    # ...
```

---

### Faza 3: Consumption Data Collector

**Service**: `kosovo-consumption-collector`

**Features:**
- Collect consumption data nga KOSTT dashboard (nÃ«se publike)
- Historical data collection
- Real-time monitoring
- Data validation me AI

---

## ğŸ”§ TeknologjitÃ« e Rekomanduara

### Python Libraries:
```txt
# Web Scraping
beautifulsoup4==4.12.2
scrapy==2.11.0
selenium==4.15.0
playwright==1.40.0

# AI/ML
openai==1.3.0
langchain==0.0.350
transformers==4.35.0
tesseract-ocr==0.1.3

# Document Processing
PyPDF2==3.0.1
pdfplumber==0.10.3
pandas==2.1.3

# API Integration
requests==2.31.0
aiohttp==3.9.1

# Scheduling
celery==5.3.4
APScheduler==3.10.4
```

---

## ğŸ“… Plan Implementimi

### Muaji 1: Weather Data Integration
- âœ… Integrim me OpenWeatherMap API
- âœ… Replace simulated weather me real data
- âœ… Testing dhe validation

### Muaji 2: Energy Price Collection
- âœ… Web scraping setup
- âœ… PDF parsing me AI
- âœ… Data validation
- âœ… Integration me analytics service

### Muaji 3: Consumption Data
- âœ… Consumption data collection
- âœ… Historical data import
- âœ… Real-time monitoring setup

### Muaji 4: AI Enhancement
- âœ… ML models pÃ«r predictions
- âœ… Anomaly detection
- âœ… Data enrichment
- âœ… Optimization

---

## ğŸ’¡ Ide ShtesÃ«

### 1. Social Media Monitoring (AI)
- Monitor Twitter/X pÃ«r power outages (Kosovo energy companies)
- Sentiment analysis pÃ«r consumer satisfaction
- Extract information nga posts (outage reports, complaints)

### 2. News Article Analysis
- Scrape news articles rreth energjisÃ« nÃ« KosovÃ«
- Use NLP pÃ«r tÃ« extract key events (blackouts, price changes, policy updates)
- Correlate me consumption patterns

### 3. Satellite Data
- Use satellite imagery pÃ«r tÃ« monitoruar solar installations
- Estimate renewable energy capacity
- Track urban development

### 4. IoT Device Integration
- Integrate me smart meters (nÃ«se publike ose partners)
- Real-time consumption data
- Granular regional data

---

## ğŸš€ Quick Start: Weather Integration

### Step 1: Krijo Weather Collector Service

```bash
mkdir -p docker/kosovo-weather-collector
cd docker/kosovo-weather-collector
```

### Step 2: Install Dependencies

```txt
# requirements.txt
requests==2.31.0
kafka-python==2.0.2
python-dotenv==1.0.0
APScheduler==3.10.4
```

### Step 3: Integro nÃ« docker-compose.yml

```yaml
kosovo-weather-collector:
  build: ./kosovo-weather-collector
  container_name: smartgrid-kosovo-weather
  environment:
    - OPENWEATHER_API_KEY=${OPENWEATHER_API_KEY}
    - KAFKA_BROKER=smartgrid-kafka:9092
    - KOSOVO_CITIES=prishtina,prizren,peje,gjilan,mitrovice
  depends_on:
    - kafka
  restart: unless-stopped
```

---

## ğŸ“Š Benefits

1. **Real Data**: ZÃ«vendÃ«soj simulated data me tÃ« dhÃ«na reale
2. **Accuracy**: MÃ« tÃ« sakta analytics dhe predictions
3. **Regional Insights**: TÃ« dhÃ«na specifike pÃ«r KosovÃ«n
4. **AI-Powered**: Automatic extraction dhe validation
5. **Scalable**: Easily extensible pÃ«r mÃ« shumÃ« burime tÃ« dhÃ«nash

---

## âš ï¸ Considerations

1. **API Limits**: Respect rate limits nga APIs
2. **Legal Compliance**: Ensure web scraping Ã«shtÃ« legal
3. **Data Privacy**: Follow GDPR dhe privacy regulations
4. **Error Handling**: Robust error handling pÃ«r API failures
5. **Caching**: Cache data pÃ«r tÃ« reduktuar API calls
6. **Cost**: Monitor API costs (OpenWeatherMap, etc.)

---

## ğŸ”— Resources pÃ«r KosovÃ«n

- **KOSTT**: https://kostt.com
- **ERO**: https://ero-ks.org
- **KEK**: https://kek-energy.com
- **ASK**: https://ask.rks-gov.net
- **Ministry of Economic Development**: https://me.rks-gov.net

---

## ğŸ“ Next Steps

1. Start me Weather Data integration (easiest, highest value)
2. Setup OpenWeatherMap API key
3. Create `kosovo-weather-collector` service
4. Test me real data
5. Expand pÃ«r mÃ« shumÃ« data sources
